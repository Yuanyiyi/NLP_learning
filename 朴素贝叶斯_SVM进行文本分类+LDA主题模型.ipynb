{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文本处理，将label和content分开"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess用于将一个文本文档进行切词，并以字符串形式输出切词结果\n",
    "path = './cnews.test.txt'\n",
    "with open(path,'r',encoding='UTF-8') as f:\n",
    "    cnews_test = f.readlines()\n",
    "# 取test中前3000出来分为2000为训练样本，1000测试样本\n",
    "cnews_test = cnews_test[500:1000]+cnews_test[1500:2000]+cnews_test[2500:3000]+cnews_test[3500:4000]+cnews_test[4500:5000]+cnews_test[5500:6000]\n",
    "# 将test中的label取出\n",
    "test_label,test_x = [],[]\n",
    "n = list(range(len(cnews_test)))\n",
    "random.shuffle(n)\n",
    "for i in n:\n",
    "    each = cnews_test[i]\n",
    "    each0 = each.split('\\t')\n",
    "    test_label.append(each0[0])\n",
    "    test_x.append(each0[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对文本内容进行分词后并以\" \"连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\lejon\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.630 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 取test中前3000出来分为2000为训练样本，1000测试样本\n",
    "import jieba\n",
    "# 使用jieba精确分词\n",
    "test_x = [[each0 for each0 in jieba.cut(each)] for each in test_x]\n",
    "test_x = [' '.join(each) for each in test_x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将3000个样本分为2500的train数据，500的test数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = test_x[:2500]\n",
    "train_y = test_label[:2500]\n",
    "test_X = test_x[2500:]\n",
    "test_y = test_label[2500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多项式模型计算文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer()\n",
    "# 该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j]表示j词在i类文本下的词频\n",
    "vector_matrix = count_vector.fit_transform(train_X)\n",
    "\n",
    "# tfidf度量模型\n",
    "train_tfidf = TfidfTransformer(use_idf=False).fit_transform(vector_matrix)\n",
    "# 将词频矩阵转化为权重矩阵，每一个特征值就是一个单词的TF-IDF值\n",
    "\n",
    "# 调用MultinomialNB分类器进行训练\n",
    "clf = MultinomialNB().fit(train_tfidf,train_y)\n",
    "\n",
    "# 测试\n",
    "test_vector = count_vector.transform(test_X)\n",
    "test_tfidf = TfidfTransformer(use_idf=False).fit_transform(test_vector)\n",
    "predict_result = clf.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以正确分类的个数，简单评测模型预测结果的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评测预测效果\n",
    "def accuracy_(test_y,predict):\n",
    "    TP,num = 0,len(test_y)\n",
    "    for i in range(num):\n",
    "        if test_y[i]==predict[i]:\n",
    "            TP+=1\n",
    "    return TP/num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多项式模型分类效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多项式模型分类效果：0.970000\n"
     ]
    }
   ],
   "source": [
    "print('多项式模型分类效果：%f'%accuracy_(test_y,predict_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "伯努利模型计算文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer()\n",
    "# 该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j]表示j词在i类文本下的词频\n",
    "vector_matrix = count_vector.fit_transform(train_X)\n",
    "\n",
    "# tfidf度量模型\n",
    "train_tfidf = TfidfTransformer(use_idf=False).fit_transform(vector_matrix)\n",
    "# 将词频矩阵转化为权重矩阵，每一个特征值就是一个单词的TF-IDF值\n",
    "\n",
    "# 调用MultinomialNB分类器进行训练\n",
    "clf = BernoulliNB().fit(train_tfidf,train_y)\n",
    "\n",
    "# 测试\n",
    "test_vector = count_vector.transform(test_X)\n",
    "test_tfidf = TfidfTransformer(use_idf=False).fit_transform(test_vector)\n",
    "predict_result = clf.predict(test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "伯努利模型分类效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "伯努利模型分类效果：0.870000\n"
     ]
    }
   ],
   "source": [
    "print('伯努利模型分类效果：%f'%accuracy_(test_y,predict_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM进行文本分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.6, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=2500,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "count_vector = CountVectorizer()\n",
    "# 该类会将文本中的词语转换为词频矩阵，矩阵元素a[i][j]表示j词在i类文本下的词频\n",
    "vector_matrix = count_vector.fit_transform(train_X)\n",
    "\n",
    "# tfidf度量模型\n",
    "train_tfidf = TfidfTransformer(use_idf=False).fit_transform(vector_matrix)\n",
    "# 将词频矩阵转化为权重矩阵，每一个特征值就是一个单词的TF-IDF值\n",
    "\n",
    "# SVM分类\n",
    "clf = svm.LinearSVC(C=1.6, class_weight=None,dual=True, fit_intercept=True,intercept_scaling=1, loss='squared_hinge',\n",
    "                        max_iter=2500,multi_class='ovr', penalty='l2', random_state=None,tol=0.0001,verbose=0)\n",
    "clf.fit(train_tfidf,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM分类效果：0.986000\n"
     ]
    }
   ],
   "source": [
    "# SVM分类测试\n",
    "test_vector = count_vector.transform(test_X)\n",
    "test_tfidf = TfidfTransformer(use_idf=False).fit_transform(test_vector)\n",
    "predict_result = clf.predict(test_tfidf)\n",
    "print('SVM分类效果：%f'%accuracy_(test_y,predict_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA部分\n",
    "获取训练矩阵和单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# 数据准备\n",
    "# preprocess用于将一个文本文档进行切词，并以字符串形式输出切词结果\n",
    "path = './cnews.test.txt'\n",
    "with open(path,'r',encoding='UTF-8') as f:\n",
    "    cnews_test = f.readlines()\n",
    "# 取test中前3000出来分为2000为训练样本，1000测试样本\n",
    "cnews_test = cnews_test[500:1500]\n",
    "# 将test中的label取出\n",
    "test_label,test_x = [],[]\n",
    "n = list(range(len(cnews_test)))\n",
    "for i in n:\n",
    "    each = cnews_test[i]\n",
    "    each0 = each.split('\\t')\n",
    "    test_label.append(each0[0])\n",
    "    test_x.append(each0[1])\n",
    "    \n",
    "# 载入停用词字典，对其进行去停用词\n",
    "with open('./stopword.txt','r',encoding='UTF-8') as f:\n",
    "    stopwords = f.readlines()\n",
    "a = ''\n",
    "for each in stopwords:\n",
    "    a = a + ' '+each\n",
    "stopwords = a.replace('\\n','').split(' ')\n",
    "stopwords = [each for each in stopwords if each not in ['\\n']]\n",
    "\n",
    "test_x = [[each0 for each0 in jieba.cut(each) if each0 not in stopwords] for each in test_x] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['科比',\n",
       " '骨折',\n",
       " ' ',\n",
       " '扣篮',\n",
       " '大伙',\n",
       " '!',\n",
       " '新浪',\n",
       " '体育讯',\n",
       " '北京',\n",
       " '时间',\n",
       " '27',\n",
       " '洛杉矶',\n",
       " '时间',\n",
       " '26',\n",
       " '消息',\n",
       " '洛杉矶',\n",
       " '湖人',\n",
       " '主场',\n",
       " '迎战',\n",
       " '新奥尔良',\n",
       " '黄蜂',\n",
       " '科比',\n",
       " '布莱恩特',\n",
       " '本场',\n",
       " '比赛',\n",
       " '带伤',\n",
       " '出战',\n",
       " '13',\n",
       " '投',\n",
       " '拿下',\n",
       " '19',\n",
       " '带领',\n",
       " '湖人',\n",
       " '106',\n",
       " '90',\n",
       " '胜利',\n",
       " '赛后',\n",
       " '发布厅',\n",
       " '接受',\n",
       " '采访',\n",
       " '赢球',\n",
       " '科比',\n",
       " '开心',\n",
       " '脸上',\n",
       " '挂',\n",
       " '笑容',\n",
       " '还',\n",
       " '不停',\n",
       " '记者',\n",
       " '开玩笑',\n",
       " '谈到',\n",
       " '脚踝',\n",
       " '情况',\n",
       " '科比',\n",
       " '脚踝',\n",
       " '僵硬',\n",
       " '打打球',\n",
       " '好',\n",
       " '越',\n",
       " '越',\n",
       " '放松',\n",
       " '最初',\n",
       " '几分钟',\n",
       " '好',\n",
       " '记者',\n",
       " '赛后',\n",
       " '兰德',\n",
       " '科比',\n",
       " '带伤',\n",
       " '打出',\n",
       " '精彩',\n",
       " '表现',\n",
       " '评价',\n",
       " '道',\n",
       " '受伤',\n",
       " '受伤',\n",
       " '科比',\n",
       " '笑',\n",
       " '结构',\n",
       " '人类',\n",
       " '科比',\n",
       " '解释',\n",
       " '拒绝',\n",
       " 'MRI',\n",
       " '原因',\n",
       " '骨折',\n",
       " '折',\n",
       " '检查',\n",
       " 'MRI',\n",
       " '浪费',\n",
       " '路上',\n",
       " '小时',\n",
       " '时间',\n",
       " '还',\n",
       " '关心',\n",
       " 'MRI',\n",
       " '科比',\n",
       " '扣篮',\n",
       " '寓意',\n",
       " '这向',\n",
       " '传达',\n",
       " '信息',\n",
       " '科比',\n",
       " '两个',\n",
       " '扣篮',\n",
       " '精彩',\n",
       " '程度',\n",
       " '堪比',\n",
       " '扣篮',\n",
       " '大赛',\n",
       " '冠军',\n",
       " '表演',\n",
       " '问道',\n",
       " '想起',\n",
       " '23',\n",
       " '24',\n",
       " '岁',\n",
       " '科比',\n",
       " '科比',\n",
       " '确实',\n",
       " '想起',\n",
       " '年轻',\n",
       " '时代',\n",
       " '确实',\n",
       " '感觉',\n",
       " '82',\n",
       " '场',\n",
       " '比赛',\n",
       " '感觉',\n",
       " '确实',\n",
       " '阿里',\n",
       " '扎',\n",
       " '17',\n",
       " '投',\n",
       " '谈到',\n",
       " '这位',\n",
       " '夺冠',\n",
       " '队友',\n",
       " '科比',\n",
       " '左拳',\n",
       " '捶',\n",
       " '捶',\n",
       " '胸膛',\n",
       " '言语',\n",
       " '包含',\n",
       " '情愫',\n",
       " '表现',\n",
       " '惊讶',\n",
       " '小弟弟',\n",
       " '对位',\n",
       " '很难',\n",
       " '长大',\n",
       " '工作',\n",
       " '灰熊',\n",
       " '马刺',\n",
       " '打成',\n",
       " '系列赛',\n",
       " '科比',\n",
       " '惊讶',\n",
       " '灰熊',\n",
       " '强大',\n",
       " '内线',\n",
       " '身材',\n",
       " '优势',\n",
       " '深度',\n",
       " '支',\n",
       " '顽强',\n",
       " '球队',\n",
       " '湖人',\n",
       " '板凳',\n",
       " '是否是',\n",
       " '对手',\n",
       " '占有优势',\n",
       " '科比',\n",
       " '开玩笑',\n",
       " '道',\n",
       " '那得',\n",
       " '板凳',\n",
       " '新浪',\n",
       " '体育',\n",
       " ' ',\n",
       " '张海彦',\n",
       " ' ',\n",
       " '发自',\n",
       " '洛杉矶',\n",
       " '\\n']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0] # 查看文本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'体育', '娱乐'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备Documnet-Term矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\n",
    "# 创建语料的词语词典，每个单独的词语都会被赋予一个索引\n",
    "dictionary = corpora.Dictionary(test_x)\n",
    "\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in test_x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建LDA模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.000*\"冯绍峰\" + 0.000*\"霸气\" + 0.000*\"项羽\" + 0.000*\"鸿门宴\" + 0.000*\"刘亦菲\"')]\n"
     ]
    }
   ],
   "source": [
    "#  使用 gensim 来创建 LDA 模型对象\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "# 在 DT 矩阵上运行和训练 LDA 模型\n",
    "ldamodel = Lda(doc_term_matrix,num_topics=1,id2word=dictionary, passes=50)\n",
    "# 输出结果\n",
    "result_lda = ldamodel.print_topics(num_topics=1,num_words=5)\n",
    "print(result_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想要得到每一个文本对应的主题，因此对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '0.010*\" \" + 0.010*\"微博\" + 0.008*\"导演\" + 0.006*\"影片\" + 0.005*\"观众\" + 0.004*\"还\" + 0.004*\"新浪\" + 0.004*\"票房\" + 0.004*\"娱乐\" + 0.003*\"拍\" + 0.003*\"拍摄\" + 0.003*\"中国\" + 0.003*\"好\" + 0.003*\"\\xa0\" + 0.003*\"角色\" + 0.003*\"演员\" + 0.003*\"\\n\" + 0.003*\"时\" + 0.002*\"戏\" + 0.002*\"主演\"'), (1, '0.010*\"比赛\" + 0.007*\"球队\" + 0.006*\" \" + 0.005*\"季后赛\" + 0.005*\"篮板\" + 0.005*\"球员\" + 0.004*\"还\" + 0.004*\"次\" + 0.004*\"时间\" + 0.004*\"新浪\" + 0.004*\"湖人\" + 0.004*\"赛季\" + 0.004*\"热火\" + 0.004*\"防守\" + 0.004*\"时\" + 0.004*\"进攻\" + 0.004*\"科比\" + 0.003*\"\\n\" + 0.003*\"马刺\" + 0.003*\"三分\"')]\n"
     ]
    }
   ],
   "source": [
    "# 创建语料的词语词典，每个单独的词语都会被赋予一个索引\n",
    "dictionary = corpora.Dictionary(test_x)\n",
    "# 使用上面的词典，将转换文档列表（语料）变成 DT 矩阵\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in test_x]\n",
    "\n",
    "#  使用 gensim 来创建 LDA 模型对象\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "# 在 DT 矩阵上运行和训练 LDA 模型\n",
    "ldamodel = Lda(doc_term_matrix,num_topics=2,id2word=dictionary, passes=50)\n",
    "# 输出结果\n",
    "result_lda = ldamodel.print_topics(num_topics=2,num_words=20)\n",
    "print(result_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "result_Lda = {}\n",
    "for each in result_lda:\n",
    "    each0 = each[1].split('+')\n",
    "    for each1 in each0:\n",
    "        each2 = each1.split('*')\n",
    "        if each2[1] in result_Lda:\n",
    "            result_Lda[each2[1]] += int(re.sub(\"\\D\",\"\",each2[0]))\n",
    "        else:\n",
    "            result_Lda[each2[1]] = int(re.sub(\"\\D\",\"\",each2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\" \" ': 16,\n",
       " '\"微博\" ': 10,\n",
       " '\"导演\" ': 8,\n",
       " '\"影片\" ': 6,\n",
       " '\"观众\" ': 5,\n",
       " '\"还\" ': 8,\n",
       " '\"新浪\" ': 8,\n",
       " '\"票房\" ': 4,\n",
       " '\"娱乐\" ': 4,\n",
       " '\"拍\" ': 3,\n",
       " '\"拍摄\" ': 3,\n",
       " '\"中国\" ': 3,\n",
       " '\"好\" ': 3,\n",
       " '\"\\xa0\" ': 3,\n",
       " '\"角色\" ': 3,\n",
       " '\"演员\" ': 3,\n",
       " '\"\\n\" ': 6,\n",
       " '\"时\" ': 7,\n",
       " '\"戏\" ': 2,\n",
       " '\"主演\"': 2,\n",
       " '\"比赛\" ': 10,\n",
       " '\"球队\" ': 7,\n",
       " '\"季后赛\" ': 5,\n",
       " '\"篮板\" ': 5,\n",
       " '\"球员\" ': 5,\n",
       " '\"次\" ': 4,\n",
       " '\"时间\" ': 4,\n",
       " '\"湖人\" ': 4,\n",
       " '\"赛季\" ': 4,\n",
       " '\"热火\" ': 4,\n",
       " '\"防守\" ': 4,\n",
       " '\"进攻\" ': 4,\n",
       " '\"科比\" ': 4,\n",
       " '\"马刺\" ': 3,\n",
       " '\"三分\"': 3}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_Lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
